{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ifIjiFbItPB5"
      },
      "source": [
        "# Fine-tuning GPT2 on Anime synopsis data\n",
        "\n",
        "This notebook attempts to understand how to fine-tune GPT2 on a specific corpus of text. In this case, the data used will be Anime Synopsis data.\n",
        "\n",
        "In order to use the GPT2 model for fine-tuning, we will use HuggingFace's `datasets` and `transformers` libraries.\n",
        "\n",
        "> Note: Run this notebook on Google Colab with GPU runtime enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQepvrzRcbmH",
        "outputId": "6f23ff36-9780-4bf6-ce7b-591d3167075b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GWwhdw4WvFLs"
      },
      "source": [
        "`GPT2LMHeadModel` is the model instance we will be using to fine-tune.\n",
        "`GPT2Tokenizer` is the corresponding tokenizer, that will perform word embedding on the text corpus given.\n",
        "\n",
        "HuggingFace also provides the `Trainer` API due to which we won't have to write custom training loops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILDvJBRDSAx_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import DataCollatorForLanguageModeling, TextDataset\n",
        "from datasets import Dataset\n",
        "\n",
        "dataset_path = \"/content/anime_gpt_data.csv\"\n",
        "output_dir = \"/content/models/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "nRFv6FUgT6ht",
        "outputId": "827d0cc7-818e-4b35-c3aa-127692a49454"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-129cf53f-34c2-4d4d-8a1d-7c9ea5509e6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>synopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|startoftext|&gt;Following their participation a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|startoftext|&gt;Music accompanies the path of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|startoftext|&gt;The Abyss—a gaping chasm stretc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|startoftext|&gt;\"In order for something to be o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|startoftext|&gt;After helping revive the legend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15189</th>\n",
              "      <td>&lt;|startoftext|&gt;All-new animation offered throu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15190</th>\n",
              "      <td>&lt;|startoftext|&gt;High school student Sora Kashiw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15191</th>\n",
              "      <td>&lt;|startoftext|&gt;After regaining her squid-like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15192</th>\n",
              "      <td>&lt;|startoftext|&gt;For years, the Niflheim Empire ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15193</th>\n",
              "      <td>&lt;|startoftext|&gt;Although Yuuta Togashi and Rikk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15194 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-129cf53f-34c2-4d4d-8a1d-7c9ea5509e6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-129cf53f-34c2-4d4d-8a1d-7c9ea5509e6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-129cf53f-34c2-4d4d-8a1d-7c9ea5509e6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                synopsis\n",
              "0      <|startoftext|>Following their participation a...\n",
              "1      <|startoftext|>Music accompanies the path of t...\n",
              "2      <|startoftext|>The Abyss—a gaping chasm stretc...\n",
              "3      <|startoftext|>\"In order for something to be o...\n",
              "4      <|startoftext|>After helping revive the legend...\n",
              "...                                                  ...\n",
              "15189  <|startoftext|>All-new animation offered throu...\n",
              "15190  <|startoftext|>High school student Sora Kashiw...\n",
              "15191  <|startoftext|>After regaining her squid-like ...\n",
              "15192  <|startoftext|>For years, the Niflheim Empire ...\n",
              "15193  <|startoftext|>Although Yuuta Togashi and Rikk...\n",
              "\n",
              "[15194 rows x 1 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "anime_df = pd.read_csv(dataset_path)\n",
        "anime_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sUV_J1jivgOS"
      },
      "source": [
        "Every synopsis starts with the token `\"<|startoftext|>\"` and ends with the `\"<|endoftext|>\"` token. In the original GPT2 model, the authors used only the latter token to determine start and end of sentences.\n",
        "\n",
        "But, we will be using a \"beginning of sentence\" token as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo3WGnfGVMxF"
      },
      "outputs": [],
      "source": [
        "anime_dataset = Dataset.from_pandas(anime_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUaWbd_HVls0",
        "outputId": "6dbb35e8-8da1-41ff-87f1-3260165ff705"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# load the tokenizer with BOS, EOS, and pad token\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\n",
        "    \"gpt2\",\n",
        "    bos_token = \"<|startoftext|>\",\n",
        "    eos_token = \"<|endoftext|>\",\n",
        "    pad_token = \"<|pad|>\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2w3KT6mVzj9"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(data):\n",
        "  return tokenizer(data['synopsis'], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "aff6ee814628438a8c291262c66f6b8b",
            "46c2ed54c5154d32812d422892a0f118",
            "2bafe8f8615f4cc7ba10071ee9605868",
            "f71e3977c19949e3b7d5edfae2039676",
            "e8b9b7cf5a8f44f3b9c2a2e0126a7a3d",
            "649337e4b4d6435f9d0504b49d48fde7",
            "3ca9c3bf46674489a10ae51f0740fb80",
            "33c95fc1ea414a1b87406a709a7c72a0",
            "5ce1b320e50d487b9c6671800d5724cb",
            "717a76f209cf4560a89febcdeaf47d65",
            "b707a97eafa34625a3293206615d95b7"
          ]
        },
        "id": "y670AFGHWfd0",
        "outputId": "f9f8efb5-aaaf-46d9-e9ec-5b34336ecbb0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aff6ee814628438a8c291262c66f6b8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15194 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "anime_dataset_preprocessed = anime_dataset.map(preprocess_dataset, batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ_qHE13WxLU",
        "outputId": "1717d4fe-17d2-4569-fe8a-3b947ee90b88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['synopsis', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 15194\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "anime_dataset_preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_-I9Eg1W0PD"
      },
      "outputs": [],
      "source": [
        "# GPT2 is not a masked language model\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer = tokenizer,\n",
        "    mlm = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NhBhqPtXKJr"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42D8Qj76XmH7",
        "outputId": "160f74a7-f253-4eb3-b658-5d7e106f3e25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(50259, 768)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGfS5hOxX7zq"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained(output_dir)\n",
        "model.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSDeIKEEYJoy",
        "outputId": "7641c53b-31c6-4e94-9cb9-03536ab30836"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI90whyoYODy",
        "outputId": "2cef9d4a-7b5f-4ea8-d54a-e6d7b790a83c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE9sy1ESY7IR"
      },
      "outputs": [],
      "source": [
        "def finetune(dataset, model, tokenizer, data_collator,\n",
        "             output_dir, overwrite_output_dir, num_train_epochs,\n",
        "             save_steps, per_device_train_batch_size):\n",
        "  training_args = TrainingArguments(\n",
        "      output_dir=output_dir,\n",
        "      overwrite_output_dir=overwrite_output_dir,\n",
        "      per_device_train_batch_size=per_device_train_batch_size,\n",
        "      num_train_epochs=num_train_epochs\n",
        "  )\n",
        "\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      data_collator=data_collator,\n",
        "      train_dataset=dataset,\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CQnTnoKagDA"
      },
      "outputs": [],
      "source": [
        "overwrite_output_dir = False\n",
        "per_device_train_batch_size = 8\n",
        "num_train_epochs = 5.0\n",
        "save_steps = 500\n",
        "output_model_dir = \"/content/animegptsan\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "N5ZYNQaEap7w",
        "outputId": "32bc1d08-d86f-475e-9b6d-cdcf07b2a15a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9500' max='9500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9500/9500 1:16:50, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.379900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.637400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.581200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.516900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>3.363500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>3.359300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>3.353100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.282100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.211200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>3.214800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>3.215400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.154800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>3.113200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>3.110000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>3.111600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>3.041800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>3.052400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>3.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>3.055100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "finetune(\n",
        "    anime_dataset_preprocessed,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    data_collator,\n",
        "    output_model_dir,\n",
        "    overwrite_output_dir,\n",
        "    num_train_epochs,\n",
        "    save_steps,\n",
        "    per_device_train_batch_size\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference\n",
        "\n",
        "Load the model from the output directory and infer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrwBWgbsuHRt"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "  my_model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "  return my_model\n",
        "\n",
        "def load_tokenizer(tok_path):\n",
        "  my_tokenizer = GPT2Tokenizer.from_pretrained(tok_path)\n",
        "  return my_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBYbU6WKvJ86"
      },
      "outputs": [],
      "source": [
        "anime_model = load_model(\"/content/animegptsan/\")\n",
        "anime_tokenizer = load_tokenizer(\"/content/models/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUCyV0B9vZGw"
      },
      "outputs": [],
      "source": [
        "def generate_text(mod, tok, sequence, max_length, opts: dict):\n",
        "  outputs = []\n",
        "  ids = tok.encode(f\"{sequence}\", return_tensors=\"pt\")\n",
        "  final_outputs = mod.generate(\n",
        "        ids,\n",
        "        do_sample=opts[\"do_sample\"],\n",
        "        max_length=max_length,\n",
        "        top_k=opts[\"top_k\"],\n",
        "        top_p=opts[\"top_p\"],\n",
        "        temperature=opts[\"temperature\"],\n",
        "        num_return_sequences=opts[\"num_return_sequences\"]\n",
        "    )\n",
        "\n",
        "  for i, out in enumerate(final_outputs):\n",
        "    output = tok.decode(out, skip_special_tokens=True)\n",
        "    outputs.append(output)\n",
        "  return outputs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change the `opts` dictionary accordingly..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6VhSWbKwCqA",
        "outputId": "0f1ac478-2c6f-4ec6-a35a-211deafd9db2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shadow realm, the land of chaos, and the realm of light. The gods of the universe have decided that the world is the center of the world's struggle for dominance and control. To the human eye, the world seems chaotic, and humans have been living in a peaceful life since ancient times. But the gods have also decided to move forward and bring the world back to its former peacefulness. This is the story of Aoyagi and the others who join forces with the gods in the search of peace. (Source: AniDB)\n",
            "Shadow realm of darkness. There exist the Demon Lords. Their leader is the Demon King, Demon Lord Grendizer. He is the master of many demon masters, but he has a secret: he can use magic for his own evil purposes. Demon Lord Ruri, along with her allies, must protect Ruri from her Demon Lord's dark desires by fighting her master and take her down to the demon realm.\n",
            "Shadow realm, where the inhabitants are called \"Toys.\" They have great power and special abilities, but these toys are not always able to fight back, especially when their opponent is a superhero called \"Superboy,\" who only appears once every three years. In the past, the Toy Kingdom of New York had existed peacefully in peace until the great city-state of Manhattan fell under the control of the Shadow. Now, the Shadow is once again controlling New York City, with his own forces of superhumans and his own secret agent named \"The Big Daddy.\"\n",
            "Shadow realm known as \"Kanagami Forest\" exists between the sky and ground. While humans enjoy peace, they are disturbed when their magic transforms into beasts. A young girl named Shima, who has been living in this forest for many years, finds herself drawn to the creatures, and discovers a dark secret. It turns out that her master is the infamous \"Cult Master\" who has turned the demon Shima into Cleveland and the demon Kyureyuu into a beast. Shima is given three choices: fight or die. Will she fight for justice, or for the power within herself that could bring about change? (Source: AniDB)\n",
            "Shadow realm of magic, war, and death! Ririno, a powerful witch who is living a normal life, fights against the evil sorcerer Lord Zuluo, his sister, Mirena, her childhood friend, and the demon lord Jizo, with her \"Magic Ring\" and sword, but there are many mysteries surrounding her. (Source: MU)\n",
            "Shadow realm. When the evil spirit King Ra has risen once again, his kingdom is now a battleground for the power-hungry Demon King Mephisto. As Mephisto continues to seek out the demon king for his own evil purposes, the kingdom is on the brink of destruction. The demon king is finally willing to save the kingdom, but he must do this with the help of three new allies.\n",
            "Shadow realm where there is an evil that steals the minds of women. The world is in turmoil due to the power of evil. The female heroes are given special powers such as the power to make others into sex slaves to the evil. One day a man named Gouda sneaks into the world of the female hero and gives birth to a baby girl called Satsuki. He can't take her anymore and kills everyone in order to make her go free.\n",
            "Shadow realm of the world where the gods and demons live. A war between the gods and demons who live in the earth. In the middle of it all, there is the kingdom of Zant. The king was a noble boy. He fought evil with the help of his sword and magic. The young warrior Kakeru fought with his sword and magic to defeat the demons and restore the kingdom. He was the first warrior to go to battle in a war. He will be known as the king of Zant. (Source: Wikipedia)\n",
            "Shadow realm, there is a mysterious world named \"Spirits Edge,\" that lies above the Heaven Realm. It is said that each year, a young girl, Suzumiya Mikami, will receive an SOS Ring. However, no one knows exactly how to enter, and Suzumiya doesn't want to waste any time when her SOS Ring is on. This is the story of Suzumiya's life when she received the SOS Ring. What is it, and where did Suzumiya's SOS Ring come from? (Source: AniDB)\n",
            "Shadow realm is the realm of humans. When a woman has sex with a wolf, her mind and body are damaged by the beast's power. The woman is left alone to keep herself healthy and happy.\n"
          ]
        }
      ],
      "source": [
        "seq = \"Shadow realm\"\n",
        "opts = {\n",
        "    \"do_sample\": True,\n",
        "    \"top_k\": 40,\n",
        "    \"top_p\": 0.9,\n",
        "    \"temperature\": 1.0,\n",
        "    \"num_return_sequences\": 10\n",
        "}\n",
        "generated = generate_text(anime_model, anime_tokenizer, seq, 200, opts)\n",
        "\n",
        "for v in generated:\n",
        "  print(v)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bafe8f8615f4cc7ba10071ee9605868": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c95fc1ea414a1b87406a709a7c72a0",
            "max": 15194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ce1b320e50d487b9c6671800d5724cb",
            "value": 15194
          }
        },
        "33c95fc1ea414a1b87406a709a7c72a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca9c3bf46674489a10ae51f0740fb80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46c2ed54c5154d32812d422892a0f118": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_649337e4b4d6435f9d0504b49d48fde7",
            "placeholder": "​",
            "style": "IPY_MODEL_3ca9c3bf46674489a10ae51f0740fb80",
            "value": "Map: 100%"
          }
        },
        "5ce1b320e50d487b9c6671800d5724cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "649337e4b4d6435f9d0504b49d48fde7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717a76f209cf4560a89febcdeaf47d65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff6ee814628438a8c291262c66f6b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46c2ed54c5154d32812d422892a0f118",
              "IPY_MODEL_2bafe8f8615f4cc7ba10071ee9605868",
              "IPY_MODEL_f71e3977c19949e3b7d5edfae2039676"
            ],
            "layout": "IPY_MODEL_e8b9b7cf5a8f44f3b9c2a2e0126a7a3d"
          }
        },
        "b707a97eafa34625a3293206615d95b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8b9b7cf5a8f44f3b9c2a2e0126a7a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f71e3977c19949e3b7d5edfae2039676": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717a76f209cf4560a89febcdeaf47d65",
            "placeholder": "​",
            "style": "IPY_MODEL_b707a97eafa34625a3293206615d95b7",
            "value": " 15178/15194 [00:19&lt;00:00, 509.47 examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
